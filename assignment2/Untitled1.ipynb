{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Core \n",
    "Used in machine learning research for better control over parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_6:0\", shape=(), dtype=float32) Tensor(\"Const_7:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#create floating point tensors \n",
    "#nodes define computational graphs, they take tensors as inputs and produce\n",
    "#tensors as outputs \n",
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) #also tf.float32 implicitly\n",
    "print (node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "#sessions encapsulate the control and state of the tensorflow runtime \n",
    "sess = tf.Session()\n",
    "print (sess.run([node1, node2]))\n",
    "#this would evaluate the nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add_3:0\", shape=(), dtype=float32)\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "node3 = tf.add(node1,node2) #operations are also nodes \n",
    "print (\"node3: \", node3)\n",
    "print (\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "#parametrized nodes have placeholders for future values \n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b #shortcut version of tf.add(a,b), adding must auto invoke\n",
    "\n",
    "print(sess.run(adder_node, {a:3, b:4.5}))\n",
    "print(sess.run(adder_node, {a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3\n",
    "print (sess.run(add_and_triple, {a:3, b:4.5} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables are trainable parameters \n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32) \n",
    "linear_model = W*x + b\n",
    "\n",
    "#unlike constants, variables are not initalized untill you call\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) #passing init subhandle to the running of our session inits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# run linear model by passing values of x to it \n",
    "print (sess.run(linear_model, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "#performing loss analysis \n",
    "y=tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model-y) #squared difference \n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print (sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W,[-1.])\n",
    "fixb = tf.assign(b,[1.]) #this is how to reassign initialized vars \n",
    "sess.run([fixW,fixb])\n",
    "print (sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # reset vals to incorrect defaults \n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "                \n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "#All code put together using tensorflow core \n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Estimator for fast implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp3yuk6448\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_model_dir': 'C:\\\\Users\\\\Raed\\\\AppData\\\\Local\\\\Temp\\\\tmp3yuk6448', '_master': '', '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_is_chief': True, '_task_id': 0, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C034D812E8>, '_session_config': None, '_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp3yuk6448\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 5.0\n",
      "INFO:tensorflow:global_step/sec: 919.223\n",
      "INFO:tensorflow:step = 101, loss = 0.0583803 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1303.71\n",
      "INFO:tensorflow:step = 201, loss = 0.00358104 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1375.65\n",
      "INFO:tensorflow:step = 301, loss = 0.000217793 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1270.51\n",
      "INFO:tensorflow:step = 401, loss = 4.85339e-05 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1385.2\n",
      "INFO:tensorflow:step = 501, loss = 2.91732e-06 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1375.65\n",
      "INFO:tensorflow:step = 601, loss = 1.5833e-07 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1338.71\n",
      "INFO:tensorflow:step = 701, loss = 1.37138e-08 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1159.58\n",
      "INFO:tensorflow:step = 801, loss = 1.33794e-09 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1511.33\n",
      "INFO:tensorflow:step = 901, loss = 1.84741e-11 (0.066 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp3yuk6448\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.54747e-12.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-03-01:20:46\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp3yuk6448\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-03-01:20:46\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.54277e-12, global_step = 1000, loss = 6.17106e-12\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-03-01:20:47\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp3yuk6448\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-03-01:20:47\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00252511, global_step = 1000, loss = 0.0101005\n",
      "train metrics: {'global_step': 1000, 'average_loss': 1.5427659e-12, 'loss': 6.1710637e-12}\n",
      "eval metrics: {'global_step': 1000, 'average_loss': 0.0025251133, 'loss': 0.010100453}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "#declare list of features, we have one numeric features \n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "#we choose the linear regression estimator \n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "#define our data\n",
    "x_train = np.array([1.,2.,3.,4.])\n",
    "y_train = np.array([0,-1.,-2.,-3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "#create helper methods \n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\":x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "#train for 1000 steps\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "#eval\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp2euzn8ih\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_model_dir': 'C:\\\\Users\\\\Raed\\\\AppData\\\\Local\\\\Temp\\\\tmp2euzn8ih', '_master': '', '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_is_chief': True, '_task_id': 0, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C04029EEF0>, '_session_config': None, '_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp2euzn8ih\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 51.4128225996\n",
      "INFO:tensorflow:global_step/sec: 1375.65\n",
      "INFO:tensorflow:step = 101, loss = 0.000201647533238 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1662.24\n",
      "INFO:tensorflow:step = 201, loss = 2.92846775481e-05 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1570.61\n",
      "INFO:tensorflow:step = 301, loss = 6.42791132377e-07 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1635\n",
      "INFO:tensorflow:step = 401, loss = 2.69934305408e-07 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1634.97\n",
      "INFO:tensorflow:step = 501, loss = 2.39427910158e-08 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1583.1\n",
      "INFO:tensorflow:step = 601, loss = 7.38987200587e-10 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1595.74\n",
      "INFO:tensorflow:step = 701, loss = 1.47126243027e-10 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1621.7\n",
      "INFO:tensorflow:step = 801, loss = 7.58759390754e-12 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1662.24\n",
      "INFO:tensorflow:step = 901, loss = 8.39927351406e-13 (0.060 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp2euzn8ih\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.98376940609e-14.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-03-01:36:03\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp2euzn8ih\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-03-01:36:03\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.02668e-13\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-03-01:36:04\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Raed\\AppData\\Local\\Temp\\tmp2euzn8ih\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-03-01:36:04\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101\n",
      "train metrics: {'global_step': 1000, 'loss': 1.0266784e-13}\n",
      "eval metrics: {'global_step': 1000, 'loss': 0.010099992}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
